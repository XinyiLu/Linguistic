This project is made of two parts: Unigram and Bigram. It uses golden section search to find the optimized alpha and beta. 

List of files:
langmod/BaseWordCounter.java  (Base abstract class for UnigramModel and BigramModel to inherit from. It includes some basic functions those two models have in common and some abstract functions for each model to implement separately. The member variable 'map' is of type HashMap and it will be initiated separately in each subclass. Different types of subclasses will initiate it with different types of keys and values.)
langmod/PlainUnigramModel.java (Plain Unigram class without padding that inherites from BaseWordCounter class. It saves the count of words into a HashMap<String,Integer> type.)
langmod/PaddedUnigramModel.java (Padded Unigram class to use when calculating the unigram smoothed probability. It inherites from PlainUnigramModel. The only difference is that it includes a padding symbol at the end of each line. It is recorded as an empty string in map.)
langmod/BigramModel.java (Bigram class inheriting from BaseWordCounter. It saves the relations between words into a HashMap<String,HashMap<String,Integer>> map. So when we try to find the count of (w,w'), we could use map.get(w).get(w') if it exists in the map. It also has a member variable with type PaddedUnigramModel to get the unigram smoothed probability when using equation 1.11. The value of parameter alpha is an input when initializing BigramModel with the PaddedUnigramModel.)
langmod/Unigram.java (Entrance function for plain unigram model)
langmod/Bigram.java  (Entrance function for bigram model)
unigram (script to run the plain unigram program)
bigram  (script to run the plain bigram program)
script  (script to compile the whole project and run unigram bigram together)

To compile it, run "javac langmod/*.java".

